{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e5691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Option 1: Will prompt for token\n",
    "# login()\n",
    "\n",
    "# Option 2: Use token directly (replace with your token)\n",
    "# login(token=\"YOUR_HF_TOKEN_HERE\")\n",
    "\n",
    "# Option 3: Read from environment variable\n",
    "# import os\n",
    "# login(token=os.environ.get(\"HF_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "393324f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fc1c7eaa654caea4fdf86efbed1df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your name?assed\n",
      "What is your name?assed\n",
      "What is your name?assed\n",
      "What is your name?assed\n",
      "What is your name?assed\n",
      "What is your name?\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-7B\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0654231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae51b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"qwedsacf/competition_math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3247e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './qwen_finetuned' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530251c34b6f4b799cbca1851805b7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(\"./qwen_finetuned\")\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\"./qwen_finetuned\")\n",
    "finetuned_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "322de19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
       "         151645,    198, 151644,    872,    198,     50,   3948,    419,  17047,\n",
       "           3491,   2041,   1667,    894,   9250,   7375,     13,  10224,    697,\n",
       "           6291,    304,   1124,  79075,  42710,  47402,   3561,    382,   5692,\n",
       "            374,    279,   3491,   1447,  11411,    400,     32,   4080,     19,\n",
       "             11,     16,    701,    425,   4080,     16,     11,     19,  15087,\n",
       "            323,    400,     34,   4080,     16,     11,     16,  15087,    525,\n",
       "            279,  17228,    315,  57960,  55114,  19360,  12947,   3555,    686,\n",
       "            387,    279,  13934,    315,    279,   2168,    315,   1459,    362,\n",
       "            421,  57960,  55114,  19360,      3,    374,  45620,    220,     24,\n",
       "             15,  12348,  65670,    911,    279,   6238,     30, 151645,    198,\n",
       "         151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a geometry level 5 problem from the dataset\n",
    "geometry_level5 = ds['train'].filter(lambda x: x.get('type') == 'Geometry' and x.get('level') == 'Level 4')\n",
    "problem = geometry_level5[2]\n",
    "\n",
    "\n",
    "# Format the problem for the model\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"Solve this geometry problem without using any external tools. Put your solution in \\\\boxed{...} format.\\n\\n Here is the problem:\\n\\n{problem['problem']}\"},\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e93958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem:\n",
      "Points $A(-4,1), B(-1,4)$ and $C(-1,1)$ are the vertices of $\\triangle ABC$. What will be the coordinates of the image of point A if $\\triangle ABC$ is rotated 90 degrees clockwise about the origin?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Model Response:\n",
      "To solve this problem, we need to apply a 90-degree clockwise rotation transformation to point A around the origin. The general rule for rotating a point (x, y) 90 degrees clockwise around the origin is to transform it into (y, -x). Applying this rule to point A(-4, 1), we get the new coordinates for the image of point A as (1, 4). Therefore, the coordinates of the image of point A after a 90-degree clockwise rotation about the origin are \\boxed{(1, 4)}.\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "outputs = finetuned_model.generate(**inputs, max_new_tokens=512)\n",
    "response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "\n",
    "print(\"Problem:\")\n",
    "print(problem['problem'])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Model Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b67d13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When we rotate images $90^{\\\\circ}$ the coordinates switch places, and the signs are adjusted based on whether or not an axis was crossed. In this case, rotating point $A$ $90^{\\\\circ}$ will bring it across the $y$-axis into Quadrant I, which means both the $x$ and $y$ will be positive. The original point $A$ was at $(-4, 1)$ so the final image will be at $(1, 4)$. We also could solve this problem by seeing that the slope of the segment from the origin to $A$ is $-1/4$. If $A$ is moving to a location that is a $90^{\\\\circ}$ rotation about the origin, it will move to a point on the segment perpendicular to the one that currently connects it to the origin. This will be the segment that has a slope of 4/1 or $-4/-1$ from the origin which puts us at $(1, 4)$ or $(-1, -4)$. The point $\\\\boxed{(1, 4)}$ is in the clockwise direction we need.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem['solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ab73ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "generated_dataset_level5 = datasets.load_from_disk('data/math_solutions_dataset_20000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aaf1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_dataset_level5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c4e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Dataset length: 553\n",
      "Dataset features: {'problem': Value('string'), 'ground_truth': Value('string'), 'solution': Value('string')}\n",
      "\n",
      "First example:\n",
      "{'problem': 'Square ABCD has its center at $(8,-8)$ and has an area of 4 square units. The top side of the square is horizontal. The square is then dilated with the dilation center at (0,0) and a scale factor of 2. What are the coordinates of the vertex of the image of square ABCD that is farthest from the origin? Give your answer as an ordered pair.', 'ground_truth': 'With the center of dilation at the origin and a scale factor of 2, all the coordinates of square $ABCD$ are twice the coordinates of its preimage. The preimage has an area of 4 square units, so its side length is 2 units. Since the center of the preimage is at $(8, -8)$, the four vertices of the preimage are at $(7, -9), (7, -7), (9, -7)$ and $(9, -9)$. The point $(9, -9)$ is the farthest from the origin on the preimage, so the point farthest from the origin on the image of square $ABCD$ is $\\\\boxed{(18, -18)}.$', 'solution': \"\\\\begin{intermediatederivation}\\nThe square has area \\\\(4\\\\), so its side length is \\\\(s=\\\\sqrt{4}=2\\\\). The half-side is \\\\(h=\\\\tfrac{s}{2}=1\\\\). With center \\\\(C=(8,-8)\\\\) and the top side horizontal, the square is axis-aligned. Thus\\n\\\\[\\nx_L=8-1=7,\\\\quad x_R=8+1=9,\\\\quad y_T=-8+1=-7,\\\\quad y_B=-8-1=-9.\\n\\\\]\\nThe four vertices are\\n\\\\[\\n(7,-7),\\\\quad (9,-7),\\\\quad (7,-9),\\\\quad (9,-9).\\n\\\\]\\nTheir squared distances from the origin are\\n\\\\[\\n98,\\\\quad 130,\\\\quad 130,\\\\quad 162,\\n\\\\]\\nrespectively, so the farthest original vertex from the origin is \\\\(V=(9,-9)\\\\).\\n\\\\end{intermediatederivation}\\n\\n\\\\begin{lemmatheorem}\\n\\\\textbf{Statement:} A dilation with center at the origin and scale factor \\\\(k\\\\) maps any point \\\\((x,y)\\\\) to \\\\((kx,ky)\\\\) and multiplies its distance from the origin by \\\\(|k|\\\\).\\n\\\\textbf{Name:} Dilation (geometry)\\n\\\\textbf{Wikipedia URL:} https://en.wikipedia.org/wiki/Dilation_(geometry)\\n\\\\textbf{Topic:} geometry\\n\\\\end{lemmatheorem}\\n\\n\\\\begin{intermediatederivation}\\nApplying the dilation with scale factor \\\\(k=2\\\\) to \\\\(V=(9,-9)\\\\) gives\\n\\\\[\\nV'=(2\\\\cdot 9,\\\\,2\\\\cdot (-9))=(18,-18).\\n\\\\]\\nSince distances from the origin scale by \\\\(2\\\\), \\\\(V'\\\\) is the farthest image vertex from the origin.\\n\\\\end{intermediatederivation}\\n\\n\\\\[\\\\boxed{(18,-18)}\\\\]\"}\n"
     ]
    }
   ],
   "source": [
    "# Reload the dataset to ensure it's loaded correctly\n",
    "from datasets import load_from_disk\n",
    "\n",
    "generated_dataset_level5 = load_from_disk('data/math_solutions_dataset_20000/')\n",
    "\n",
    "# Check the dataset structure\n",
    "print(f\"Dataset type: {type(generated_dataset_level5)}\")\n",
    "print(f\"Dataset length: {len(generated_dataset_level5)}\")\n",
    "if hasattr(generated_dataset_level5, 'features'):\n",
    "    print(f\"Dataset features: {generated_dataset_level5.features}\")\n",
    "    print(f\"\\nFirst example:\")\n",
    "    print(generated_dataset_level5[0])\n",
    "else:\n",
    "    print(f\"Error: Dataset is not a proper Dataset object. It's a {type(generated_dataset_level5)}\")\n",
    "    print(f\"First item: {generated_dataset_level5[0] if len(generated_dataset_level5) > 0 else 'empty'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8526637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Square ABCD has its center at $(8,-8)$ and has an area of 4 square units. The top side of the square is horizontal. The square is then dilated with the dilation center at (0,0) and a scale factor of 2. What are the coordinates of the vertex of the image of square ABCD that is farthest from the origin? Give your answer as an ordered pair.',\n",
       " 'ground_truth': 'With the center of dilation at the origin and a scale factor of 2, all the coordinates of square $ABCD$ are twice the coordinates of its preimage. The preimage has an area of 4 square units, so its side length is 2 units. Since the center of the preimage is at $(8, -8)$, the four vertices of the preimage are at $(7, -9), (7, -7), (9, -7)$ and $(9, -9)$. The point $(9, -9)$ is the farthest from the origin on the preimage, so the point farthest from the origin on the image of square $ABCD$ is $\\\\boxed{(18, -18)}.$',\n",
       " 'solution': \"\\\\begin{intermediatederivation}\\nThe square has area \\\\(4\\\\), so its side length is \\\\(s=\\\\sqrt{4}=2\\\\). The half-side is \\\\(h=\\\\tfrac{s}{2}=1\\\\). With center \\\\(C=(8,-8)\\\\) and the top side horizontal, the square is axis-aligned. Thus\\n\\\\[\\nx_L=8-1=7,\\\\quad x_R=8+1=9,\\\\quad y_T=-8+1=-7,\\\\quad y_B=-8-1=-9.\\n\\\\]\\nThe four vertices are\\n\\\\[\\n(7,-7),\\\\quad (9,-7),\\\\quad (7,-9),\\\\quad (9,-9).\\n\\\\]\\nTheir squared distances from the origin are\\n\\\\[\\n98,\\\\quad 130,\\\\quad 130,\\\\quad 162,\\n\\\\]\\nrespectively, so the farthest original vertex from the origin is \\\\(V=(9,-9)\\\\).\\n\\\\end{intermediatederivation}\\n\\n\\\\begin{lemmatheorem}\\n\\\\textbf{Statement:} A dilation with center at the origin and scale factor \\\\(k\\\\) maps any point \\\\((x,y)\\\\) to \\\\((kx,ky)\\\\) and multiplies its distance from the origin by \\\\(|k|\\\\).\\n\\\\textbf{Name:} Dilation (geometry)\\n\\\\textbf{Wikipedia URL:} https://en.wikipedia.org/wiki/Dilation_(geometry)\\n\\\\textbf{Topic:} geometry\\n\\\\end{lemmatheorem}\\n\\n\\\\begin{intermediatederivation}\\nApplying the dilation with scale factor \\\\(k=2\\\\) to \\\\(V=(9,-9)\\\\) gives\\n\\\\[\\nV'=(2\\\\cdot 9,\\\\,2\\\\cdot (-9))=(18,-18).\\n\\\\]\\nSince distances from the origin scale by \\\\(2\\\\), \\\\(V'\\\\) is the farthest image vertex from the origin.\\n\\\\end{intermediatederivation}\\n\\n\\\\[\\\\boxed{(18,-18)}\\\\]\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_dataset_level5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e971d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m filtered_dataset = \u001b[43mdataset\u001b[49m.load_from_disk(\u001b[33m'\u001b[39m\u001b[33mnewopenaioutputs/transformed_solutions_qwen2-math-7b-instruct_filtered\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_dataset = datasets.load_from_disk('newopenaioutputs/transformed_solutions_qwen2-math-7b-instruct_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a65d1b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfiltered_dataset\u001b[49m.num_rows\n",
      "\u001b[31mNameError\u001b[39m: name 'filtered_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd12710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
