"""
Transform Qwen-generated proofs using OpenAI API to new format.
Takes proofs from Qwen 7B model and transforms them using OpenAI.
"""

import os
import json
from typing import List, Dict
from openai import OpenAI
import datasets
from tqdm import tqdm


def get_api_key():
    """Get API key from settings.json or environment variable."""
    settings_path = os.path.join(os.path.dirname(__file__), "settings.json")
    if os.path.exists(settings_path):
        with open(settings_path, "r") as f:
            settings = json.load(f)
            api_key = settings.get("openai_api_key")
            if api_key:
                return api_key
    return os.getenv("OPENAI_API_KEY")


def transform_proof_with_openai(client: OpenAI, old_proof: str, problem: str) -> str:
    """Transform a proof using OpenAI API."""
    transform_prompt = """Transform the following mathematical proof into the structured format below. The proof was generated by a 7B model and may need reformatting.

**Original Problem:**
{problem}

**Original Proof:**
{old_proof}

Transform this proof into the following format:

Generate a detailed, step-by-step mathematical proof. For each step, output the reasoning using exactly one of two tags:  
- **<LEMMA_THEOREM_TAG>…</LEMMA_THEOREM_TAG>:** Use this tag for any step that cites a lemma or theorem from Wikipedia. Inside this tag, include:  
   - the statement of the lemma/theorem,  
   - the name of the lemma/theorem,  
   - the relevant Wikipedia page address (URL),  
   - the mathematical topic (e.g., geometry, algebra, topology, probability, combinatorics, optimization, etc.).
- **<INTERMEDIATE_DERIVATION_TAG>…</INTERMEDIATE_DERIVATION_TAG>:** Use this tag for reasoning or logical derivation steps that link information together, interpret results, or manipulate equations based on previous steps or lemmas/theorems.

Write the final answer in the \\boxed{{}} math environment.

**Guidelines:**
- Ensure that each reasoning process and justification appears **before** any conclusions or derivations.  
- Each tag block should encompass one logical or justification step.
- Always write the final answer in the \\boxed{{}} environment as a standalone line.
- Preserve all mathematical content and reasoning from the original proof.
""".format(problem=problem, old_proof=old_proof)
    
    try:
        response = client.responses.create(
            prompt={
                "id": "pmpt_69475c3f5c9c8194b0a136dc663d15b30cc8e7bedee1d50b",
                "version": "2"
            },
            input=[{"role": "user", "content": transform_prompt}],
            reasoning={
                "summary": "auto"
            },
            include=[
                "reasoning.encrypted_content",
                "web_search_call.action.sources"
            ]
        )
        return response.output_text
    except Exception as e:
        return f"Error: {str(e)}"


def load_qwen_solutions(input_path: str) -> List[Dict]:
    """Load Qwen-generated solutions from JSONL file."""
    results = []
    with open(input_path, "r") as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    return results


def transform_solutions(
    input_path: str,
    output_jsonl_path: str,
    output_dataset_path: str = None
):
    """Transform Qwen solutions using OpenAI API."""
    api_key = get_api_key()
    if not api_key:
        raise ValueError(
            "OpenAI API key required. Set OPENAI_API_KEY environment variable "
            "or add 'openai_api_key' to settings.json file."
        )
    
    client = OpenAI(api_key=api_key)
    
    # Load Qwen-generated solutions
    print(f"Loading solutions from {input_path}...")
    qwen_results = load_qwen_solutions(input_path)
    print(f"Loaded {len(qwen_results)} solutions")
    
    # Transform each solution
    transformed_results = []
    for item in tqdm(qwen_results, desc="Transforming"):
        problem = item.get("problem", "")
        old_proof = item.get("generated_solution", "")
        ground_truth = item.get("ground_truth", "")
        
        # Transform proof using OpenAI
        new_proof = transform_proof_with_openai(client, old_proof, problem)
        
        transformed_results.append({
            "problem": problem,
            "ground_truth": ground_truth,
            "old_proof": old_proof,  # Original Qwen proof
            "new_proof": new_proof,  # OpenAI-transformed proof
        })
    
    # Save as JSONL
    os.makedirs(os.path.dirname(output_jsonl_path) if os.path.dirname(output_jsonl_path) else ".", exist_ok=True)
    with open(output_jsonl_path, "w") as f:
        for result in transformed_results:
            f.write(json.dumps(result) + "\n")
    print(f"Saved JSONL to {output_jsonl_path}")
    
    # Save as HuggingFace Dataset
    if output_dataset_path:
        dataset = datasets.Dataset.from_list(transformed_results)
        dataset.save_to_disk(output_dataset_path)
        print(f"Saved dataset to {output_dataset_path}")


def main():
    # Configuration
    input_path = "generated_solutions_level4.jsonl"  # Qwen-generated solutions
    output_jsonl_path = "transformed_solutions_level4.jsonl"
    output_dataset_path = "transformed_solutions_level4_dataset"
    
    transform_solutions(
        input_path=input_path,
        output_jsonl_path=output_jsonl_path,
        output_dataset_path=output_dataset_path
    )


if __name__ == "__main__":
    main()

